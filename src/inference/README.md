# Измерение производительности вывода глубоких моделей

Система бенчмаркинга поддерживает следующие фреймворки для вывода
глубоких моделей:

1. Inference Engine в составе Intel® Distribution of OpenVINO™ Toolkit
   (синхронный и асинхронный программный интерфейс).
1. Intel® Optimization for Caffe.
1. Intel® Optimization for TensorFlow.
1. TensorFlow Lite.
1. MXNet.

## Вывод глубоких моделей с использованием Inference Engine

### Вывод глубоких моделей средствами синхронного интерфейса

#### Аргументы командной строки

Название скрипта:

```bash
inference_sync_mode.py
```

Обязательные аргументы:

- `-m / --model` - путь до xml-файла с описанием модели.
- `-w / --weights` - путь до бинарного файла, содержащего веса обученной модели.
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один прямой проход по сети. По умолчанию равно `1`.
- `-l / --extension` - абсолютный путь к библиотеке
  с реализацией нестандартных слоев для устройств `CPU` и `MYRIAD`.
- `-c / --cldnn_config` - абсолютный путь к библиотеке с реализацией
  нестандартных слоев для устройства `GPU`.
- `-d / --device` - оборудование (`CPU`, `GPU`, `FPGA`, `MYRIAD`),
  на котором будет выполняться вывод сети. По умолчанию вывод осуществляется
  на `CPU`. Также доступны режимы геторогенного исполнения, при котором слои
  сети распределяются между устройствамии, и вывод с одновременным использованием
  нескольких устройств, при котором запросы распределяются между устройствами
  (`HETERO:<Device1>,<Device2>,..`,  `MULTI:<Device1>,<Device2>,..`).
- `--dump` - флаг сохранения информации об исполнении модели.
- `-p / --priority` - приоритет устройств для вывода с использованием нескольких
  устройств.
- `--labels` - путь до файла с перечнем меток классов при решении задачи.
  По умолчанию интерпретация выхода сети не выполняется.
- `-nt / --number_top` - количество лучших результатов, выводимых
  при решении задачи классификации. По умолчанию выводится `10` наилучших
  результатов.
- `-ni / --number_iter` - количество прямых проходов по сети. По умолчанию
  выполняется один проход по сети.
- `-nthreads / --number_threads` - максимальное число потоков для исполнения вывода.
  По умолчанию будет использоваться количество потоков, равное числу физических
  ядер в системе.
- `-t / --task` - наименование решаемой задачи. Для просмотра доступных
  задач используйте следующую команду:

  ```bash
  python3 inference_sync_mode.py -h
  ```

- `--color_map` - путь до карты цветов при решении задачи семантической
  сегментации изображений.
- `--prob_threshold` - порог вероятности для фильтрации результатов и 
  отбрасывания лишних окаймляющих прямоугольников  при решении задачи детектирования
  объектов. По умолчанию равен `0.5`.
- `-mi / -mininfer` - минимальное допустимое время выполнения вывода.
  По умолчанию равно нулю.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.

#### Примеры запуска

**Командная строка для решения задачи классификации изображений**

```bash
python3 inference_sync_mode.py \
    -t classification -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin \
    --labels <path_to_labels>/image_net_synset.txt
```

Результат выполнения: набор наиболее вероятных классов, которым принадлежит
изображение.

**Командная строка для решения задачи детектирования объектов**

```bash
python3 inference_sync_mode.py \
    -t detection -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin
```

Результат выполнения: набор окаймляющих прямоугольников, соответствующих
обнаруженным объектам, изображение, разрешение которого совпадает с разрешением
входного изображения, на котором отображены окаймляющие прямоугольники.

**Командная строка для решения задачи семантической сегментации изображений**

```bash
python3 inference_sync_mode.py \
    -t segmentation -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin \
    --color_map <path_to_color_map>/color_map.txt
```

Результат выполнения: изображение, разрешение которого совпадает с разрешением
входного изображения; интенсивность пикселя соответствует классу объектов,
которому принадлежит данная точка на изображении.

### Вывод глубоких моделей средствами асинхронного интерфейса

#### Аргументы командной строки

Название скрипта:

```bash
inference_async_mode.py
```

Обязательные аргументы:

- `-m / --model` - путь до xml-файла с описанием модели.
- `-w / --weights` - путь до бинарного файла, содержащего веса обученной модели.
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-r / --request` - количество запросов на одновременное выполнения вывода.
  По умолчанию выставляется оптимальное количество запросов, подбирается
  автоматически при использовании асинхронного интерфейса в OpenVINO.
- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-l / --extension` - абсолютный путь к библиотеке 
  с реализацией нестандартных слоев для устройств `CPU` и `MYRIAD`.
- `-c / --cldnn_config` - абсолютный путь к библиотеке с реализацией
  нестандартных слоев для устройства `GPU`.
- `-d / --device` - оборудование (`CPU`, `GPU`, `FPGA`, `MYRIAD`),
  на котором будет выполнен прямой проход по сети. По умолчанию вывод осуществляется
  на `CPU`. Также доступны режимы геторогенного исполнения, при котором слои
  сети распределяются между устройствамии, и вывод с одновременным использованием
  нескольких устройств, при котором запросы распределяются между устройствами
  (`HETERO:<Device1>,<Device2>,..`,  `MULTI:<Device1>,<Device2>,..`).
- `--dump` - флаг для сохранения информации об исполнении модели.
- `-p / --priority` - приоритет устройств для вывода с использованием нескольких
  устройств.
- `--labels` - путь до файла с перечнем меток при решении задачи.
  По умолчанию обработка выхода не производится.
- `-nt / --number_top` - число лучших результатов, выводимых
  при решении задачи классификации. По умолчанию выводится `10` наилучших
  результатов.
- `-ni / --number_iter` - количество прямых проходов сети. По умолчанию
  выполняется один проход сети.
- `-nthreads / --number_threads` - максимальное число потоков для исполнения вывода.
  По умолчанию будет использоваться максимальное количество потоков в системе.
- `-nstreams / --number_streams` - максимальное число логических потоков для исполнения
  вывода. По умолчанию выставляется оптимальное значение, подобранное автоматически
  средствами OpenVINO. Оптимальное значение зависит от исполняемого устройства.
- `-t / --task` - наименование решаемой задачи. Для просмотра списка задач используйте
  следующую команду:

  ```bash
  python3 inference_async_mode.py -h
  ```

- `--color_map` - путь до карты цветов при решении задачи семантической
  сегментации.
- `--prob_threshold` - порог вероятности для фильтрации результатов и 
  отбрасывания лишних окаймляющих прямоугольников при решении задачи детектирования
  объектов. По умолчанию равен `0.5`.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.

#### Примеры запуска

**Командная строка для решения задачи классификации изображений**

```bash
python3 inference_async_mode.py \
    -t classification -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin \
    --labels <path_to_labels>/image_net_synset.txt
```

Результат выполнения: набор наиболее вероятных классов, которым принадлежит
изображение.

**Командная строка для решения задачи детектирования объектов**

```bash
python3 inference_async_mode.py \
    -t detection -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin
```

Результат выполнения: набор окаймляющих прямоугольников, соответствующих
обнаруженным объектам; изображение, разрешение которого совпадает с разрешением
входного изображения, на котором отображены окаймляющие прямоугольники.

**Командная строка для решения задачи семантической сегментации изображений**

```bash
python3 inference_async_mode.py \
    -t segmentation -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin \
    --color_map <path_to_color_map>/color_map.txt
```

Результат выполнения: изображение, разрешение которого совпадает с разрешением
входного изображения; интенсивность пикселя соответствует классу объектов,
которому принадлежит даннная точка на изображении.

## Вывод глубоких моделей с использованием Intel Optimization for Caffe

#### Аргументы командной строки

Название скрипта:

```bash
inference_caffe.py
```

Обязательные аргументы:

- `-m / --model` - путь до prototxt-файла с описанием модели.
- `-w / --weights` - путь до caffemodel-файла, содержащего веса обученной модели.
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-d / --device` - оборудование, на котором будет выполнен проход сети. 
  В данный момент вывод осуществляется только на `CPU`.
- `--labels` - путь до файла с перечнем меток при решении задачи.
- `-nt / --number_top` - количество лучших результатов, выводимых
  при решении задачи классификации. По умолчанию выводится `10` наилучших
  результатов.
- `-ni / --number_iter` - количество прямых проходов сети. По умолчанию
  выполняется один проход сети.
- `-t / --task` - наименование решаемой задачи (`classification`, 
  `detection`, `segmentation`). По умолчанию обработка выхода не производится.
- `--color_map` - путь до карты цветов при решении задачи семантической
  сегментации.
- `--prob_threshold` - порог вероятности для фильтрации результатов и 
  отбрасывания лишних окаймляющих прямоугольников при решении задачи детектирования
  объектов. По умолчанию равен `0.5`.
- `--channel_swap` - порядок перестановки цветовых каналов изображения. Загрузка
  изображений осуществляется в формате BGR (порядок соответствует `(0, 1, 2)`),
  а большинство нейронных сетей принимают на вход изображения в формате RGB,
  поэтому по умолчанию порядок `(2, 1, 0)`.
- `--input_scale` - коэффициент масштабирования изображения. По умолчанию равен `1`.
- `--mean` - параметры для вычитания средних по каждому цветовому каналу изображения.
  По умолчанию `(0, 0, 0)`.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.

#### Примеры запуска

**Командная строка для решения задачи классификации изображений**

```bash
python3 inference_caffe.py \
    -t classification -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.prototxt \
    -w <path_to_weights>/<model_name>.caffemodel \
    --labels <path_to_labels>/image_net_synset.txt
```

Результат выполнения: набор наиболее вероятных классов, которым принадлежит
изображение.

**Командная строка для решения задачи детектирования объектов**

```bash
python3 inference_caffe.py \
    -t detection -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.prototxt \
    -w <path_to_weights>/<model_name>.caffemodel
```

Результат выполнения: набор окаймляющих прямоугольников, соответствующих
обнаруженным объектам; изображение, разрешение которого совпадает с разрешением
входного изображения, на котором отрисованы окаймляющие прямоугольники.

**Командная строка для решения задачи семантической сегментации изображений**

```bash
python3 inference_caffe.py \
    -t segmentation -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.prototxt \
    -w <path_to_weights>/<model_name>.caffemodel \
    --color_map <path_to_color_map>/color_map.txt
```

Результат выполнения: изображение, разрешение которого совпадает с разрешением
входного изображения; интенсивность пикселя соответствует классу объектов,
которому принадлежит даннная точка на изображении.

## Вывод глубоких моделей с использованием Intel Optimization for TensorFlow

#### Аргументы командной строки

Название скрипта:

```bash
inference_tensorflow.py
```

Обязательные аргументы:

- `-m / --model` - путь до pb-файла или meta-файла с обученной глубокой моделью.
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-d / --device` - оборудование, на котором будет выполнен проход сети. 
  В данный момент вывод осуществляется только на `CPU`.
- `-l / --labels` - путь до файла с перечнем меток при решении задачи.
- `-nt / --number_top` - количество лучших результатов, выводимых
  при решении задачи классификации. По умолчанию выводится `10` наилучших
  результатов.
- `-ni / --number_iter` - количество прямых проходов по сети. По умолчанию
  выполняется один проход по сети.
- `-t / --task` - наименование решаемой задачи (`classification`, 
  `detection`, `yolo_tiny_voc`, `yolo_v2_coco`, `yolo_v2_tiny_coco`,
  `yolo_v3_tf`, `mask-rcnn`). По умолчанию обработка выхода не выполняется.
- `--prob_threshold` - порог вероятности для фильтрации результатов и 
  отбрасывания лишних окаймляющих прямоугольников  при решении задачи детектирования
  объектов. По умолчанию равен `0.5`.
- `--channel_swap` - порядок перестановки цветовых каналов изображения. Загрузка
  изображений осуществляется в формате BGR (порядок соответствует `(0, 1, 2)`),
  а большинство нейронных сетей принимают на вход изображения в формате RGB,
  поэтому по умолчанию порядок `(2, 1, 0)`.
- `--input_scale` - коэффициент масштабирования изображения. По умолчанию равен `1`.
- `--mean` - параметры для вычитания средних по каждому цветовому каналу изображения.
  По умолчанию `(0, 0, 0)`.
- `--input_shape` - размеры входного тензора в формате HWC (высота, ширина, число 
  каналов). По умолчанию не установлен.
- `--input_names` - название входного узла модели. По умолчанию не установлен.
- `--output_names` - имена выходных узлов модели. По умолчанию не установлен.
- `--num_inter_threads` - количество потоков, используемых для параллелизма
  между независимыми операциями. По умолчанию не установлен и выбирается
  TensorFlow автоматически.
- `--num_intra_threads` - количество потоков, используемых для параллелизма
  между блокирующими операциями. По умолчанию не установлен и выбирается
  TensorFlow автоматически.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.

#### Примеры запуска

**Командная строка для решения задачи классификации изображений**

```bash
python3 inference_tensorflow.py \
    -t classification -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.pb \
    --labels <path_to_labels>/image_net_synset.txt
```

Результат выполнения: набор наиболее вероятных классов, которым принадлежит
изображение.

**Командная строка для решения задачи детектирования объектов**

```bash
python3 inference_tensorflow.py \
    -t detection -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.pb \
```

Результат выполнения: набор окаймляющих прямоугольников, соответствующих
обнаруженным объектам; изображение, разрешение которого совпадает с разрешением
входного изображения, на котором отрисованы окаймляющие прямоугольники.


## Вывод глубоких моделей с использованием TensorFlow Lite

#### Аргументы командной строки

Название скрипта:

```bash
inference_tensorflowlite.py
```

Обязательные аргументы:

- `-m / --model` - путь до tflite-файла с обученной глубокой моделью.
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-d / --device` - оборудование, на котором будет выполнен проход сети. 
  В данный момент вывод осуществляется только на `CPU`.
- `-ni / --number_iter` - количество прямых проходов по сети. По умолчанию
  выполняется один проход по сети.
- `-t / --task` - наименование решаемой задачи (`classification`, 
  `detection`, `yolo_tiny_voc`, `yolo_v2_coco`, `yolo_v2_tiny_coco`,
  `yolo_v3_tf`, `mask-rcnn`). По умолчанию обработка выхода не выполняется.
- `--channel_swap` - порядок перестановки цветовых каналов изображения. Загрузка
  изображений осуществляется в формате BGR (порядок соответствует `(0, 1, 2)`),
  а большинство нейронных сетей принимают на вход изображения в формате RGB,
  поэтому по умолчанию порядок `(2, 1, 0)`.
- `--input_scale` - коэффициент масштабирования изображения. По умолчанию равен `1`.
- `--mean` - параметры для вычитания средних по каждому цветовому каналу изображения.
  По умолчанию `(0, 0, 0)`.
- `--input_shape` - размеры входного тензора в формате HWC (высота, ширина, число 
  каналов). По умолчанию не установлен.
- `--input_names` - название входного узла модели. По умолчанию не установлен.
- `--output_names` - имена выходных узлов модели. По умолчанию не установлен.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `--layout` - формат входного тензора. По умолчанию `NHWC`.
- `-nthreads / --number_threads` - максимальное число потоков для исполнения вывода.
  По умолчанию будет использоваться количество потоков, равное числу физических
  ядер в системе.
- `--delegate_ext` - путь до библиотеки с аппаратным ускорением моделей. По умолчанию не установлен.
- `--delegate_options` - настройки для библиотеки с аппаратным ускорением моделей
  в формате "option1: value1; option2: value2". По умолчанию не установлены.

#### Примеры запуска

```bash
python3 inference_tensorflowlite.py \
    -m <path_to_model>/<model_name>.tflite \
    -i <path_to_image>/<image_name>
```

## Вывод глубоких моделей с использованием MXNet (Gluon API)

#### Аргументы командной строки

Название скрипта:

```bash
inference_mxnet.py
```

Обязательные аргументы:

- `-m / --model` - путь до описания архитектуры модели
  в формате `.json`, если модель загружается из файла.
  Модель должна быть обучена с использованием Gluon API
  и экспортирована с помощью метода `export`.
- `-w / --weights` - путь до весов обученной модели,
  которые хранятся в файле расширением `.params`,
  если модель загружается из файла. Модель должна быть
  обучена с использованием Gluon API и экспортирована
  с помощью метода `export`.
- `-mn / --model_name` - название модели, если модель
  загружается из [Gluon Model Zoo][gluon_modelzoo].
  При таком варианте запуска модель загружается из сети Интернет.
- `-i / --input` - путь до изображения или директории
  с изображениями (расширения файлов `.jpg`, `.png`,
  `.bmp` и т.д.).
- `-is / --input_shape` - размеры входного тензора сети в формате
  BxCxWxH, B - размер пачки, C - количество каналов изображений,
  W - ширина изображений, H - высота изображений.

Опциональные аргументы:

- `-t / --task` - название задачи. Текущая реализация поддерживает
  решение задачи классификации. По умолчанию принимает значение
  `classification`.
- `-in / --input_name` - название входа модели. По умолчанию модель
  имеет один вход с названием `data`. Текущая реализация вывода
  предусматривает наличие только одного входа.
- `--norm` - флаг необходимости нормировки изображений.
  Выполняется с использованием функции ` mxnet.image.color_normalize`.
  Среднее и среднеквадратическое отклонение, которые принимаются
  на вход указываются в следующих двух аргументах.
- `--mean` - среднее значение интенсивности, которое вычитается
  из изображений в процессе нормировки. Для классификационных моделей
  из [Gluon Model Zoo][gluon_modelzoo], которые обучены на наборе
  данных ImageNet, значение равно `0.485 0.456 0.406`. По умолчанию
  данный параметр принимает значение `0 0 0`.
- `--std` - среднеквадратическое отклонение интенсивности, на которое
  делится значение интенсивности каждого пикселя входного изображения
  в процессе нормировки. Для классификационных моделей
  из [Gluon Model Zoo][gluon_modelzoo], которые обучены на наборе
  данных ImageNet, значение равно `0.229 0.224 0.225`. По умолчанию
  данный параметр принимает значение `1 1 1`.
- `--channel_swap` - порядок перестановки цветовых каналов изображения.
  Загрузка изображений осуществляется в формате BGR (порядок
  соответствует `(0, 1, 2)`), а большинство нейронных сетей принимают
  на вход изображения в формате RGB, поэтому по умолчанию порядок
  `(2, 1, 0)`.
- `-d / --device` - оборудование, на котором выполняется вывод сети.
  Поддерживается вывод на CPU (значение параметра `CPU`) и NVIDIA GPU
  (значение параметра `GPU`). По умолчанию принимает значение `CPU`.
- `-l / --labels`- путь до файла в формате JSON с перечнем меток
  при решении задачи. По умолчанию принимает значение
  `image_net_labels.json`, что соответствует меткам набора данных
  ImageNet.
- `-ni / --number_iter` - количество прямых проходов по сети.
  По умолчанию выполняется один проход по сети.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `-s / --save_model` - флаг, который определяет необходимость сохранения
  модели, загруженной средствами GluonCV API из репозитория моделей.
  По умолчанию модель не сохраняется. Наличие данной опции обусловлено
  необходимостью последующего запуска компонента Accuracy Checker
  для проверки качества работы модели.
- `-p / --path_save_model` - путь для сохранения файлов модели.
  В процессе сохранения внутри указанной директории создается
  вложенная директория с названием модели `<model_name>`.
  Формируется два файла: `<model_name>-0000.params` - бинарный файл
  с обученными параметрами модели, `<model_name>-symbol.json` - архитектура
  модели в формате .json. По умолчанию модель сохраняется в текущей
  директории.

#### Примеры запуска

**Запуск вывода для модели, которая загружается из Gluon Model Zoo**

```bash
python inference_mxnet.py --model_name <model_name> \
                          --input <path_to_data> \
                          --input_name <input_name> \
                          --input_shape <input_shape> \
                          --norm --mean <mean> --std <std> \
                          --batch_size <batch_size> \
                          --save_model --path_save_model <path_save_model>
```

**Запуск вывода для модели, которая загружается из файлов**

```bash
python inference_mxnet.py --model <file_name>.json \
                          --weights <file_name>.params \
                          --input_name <input_name> \
                          --input_shape <input_shape> \
                          --input <path_to_data> \
                          --labels <label_file>.json \
                          --batch_size <batch_size>
```


<!-- LINKS -->
[gluon_modelzoo]: https://cv.gluon.ai/model_zoo/index.html
