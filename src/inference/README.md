# Измерение производительности вывода глубоких моделей

Система бенчмаркинга поддерживает следующие фреймворки для вывода
глубоких моделей:

1. Inference Engine в составе Intel® Distribution of OpenVINO™ Toolkit
   (синхронный и асинхронный программный интерфейс).
1. Caffe.
1. TensorFlow.
1. TensorFlow Lite.
1. MXNet.
1. PyTorch.
1. ONNX Runtime.
1. Apache TVM.
1. Deep Graph Library (DGL, PyTorch-based).
1. RKNN.
1. ncnn.
1. Spektral.

## Вывод глубоких моделей с использованием Inference Engine

### Вывод глубоких моделей средствами синхронного интерфейса

#### Аргументы командной строки

Название скрипта:

```bash
inference_openvino_sync_mode.py
```

Обязательные аргументы:

- `-m / --model` - путь до xml-файла с описанием модели.
- `-w / --weights` - путь до бинарного файла, содержащего веса обученной модели.
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один прямой проход по сети. По умолчанию равно `1`.
- `-l / --extension` - абсолютный путь к библиотеке
  с реализацией нестандартных слоев для устройств `CPU` и `MYRIAD`.
- `-c / --cldnn_config` - абсолютный путь к библиотеке с реализацией
  нестандартных слоев для устройства `GPU`.
- `-d / --device` - оборудование (`CPU`, `GPU`, `FPGA`, `MYRIAD`),
  на котором будет выполняться вывод сети. По умолчанию вывод осуществляется
  на `CPU`. Также доступны режимы геторогенного исполнения, при котором слои
  сети распределяются между устройствамии, и вывод с одновременным использованием
  нескольких устройств, при котором запросы распределяются между устройствами
  (`HETERO:<Device1>,<Device2>,..`,  `MULTI:<Device1>,<Device2>,..`).
- `--dump` - флаг сохранения информации об исполнении модели.
- `-p / --priority` - приоритет устройств для вывода с использованием нескольких
  устройств.
- `--labels` - путь до файла с перечнем меток классов при решении задачи.
  По умолчанию интерпретация выхода сети не выполняется.
- `-nt / --number_top` - количество лучших результатов, выводимых
  при решении задачи классификации. По умолчанию выводится `10` наилучших
  результатов.
- `-ni / --number_iter` - количество прямых проходов по сети. По умолчанию
  выполняется один проход по сети.
- `-nthreads / --number_threads` - максимальное число потоков для исполнения вывода.
  По умолчанию будет использоваться количество потоков, равное числу физических
  ядер в системе.
- `-t / --task` - наименование решаемой задачи. Для просмотра доступных
  задач используйте следующую команду:

  ```bash
  python3 inference_openvino_sync_mode.py -h
  ```

- `--color_map` - путь до карты цветов при решении задачи семантической
  сегментации изображений.
- `--prob_threshold` - порог вероятности для фильтрации результатов и
  отбрасывания лишних окаймляющих прямоугольников при решении задачи детектирования
  объектов. По умолчанию равен `0.5`.
- `-mi / -mininfer` - минимальное допустимое время выполнения вывода.
  По умолчанию равно нулю.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `--time` - время выполнения прямых проходов по сети.
- `--report_path` - путь до файла с отчетом в формате `.json`.

#### Примеры запуска

**Командная строка для решения задачи классификации изображений**

```bash
python3 inference_openvino_sync_mode.py \
    -t classification -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin \
    --labels <path_to_labels>/image_net_synset.txt
```

Результат выполнения: набор наиболее вероятных классов, которым принадлежит
изображение.

**Командная строка для решения задачи детектирования объектов**

```bash
python3 inference_openvino_sync_mode.py \
    -t detection -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin
```

Результат выполнения: набор окаймляющих прямоугольников, соответствующих
обнаруженным объектам, изображение, разрешение которого совпадает с разрешением
входного изображения, на котором отображены окаймляющие прямоугольники.

**Командная строка для решения задачи семантической сегментации изображений**

```bash
python3 inference_openvino_sync_mode.py \
    -t segmentation -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin \
    --color_map <path_to_color_map>/color_map.txt
```

Результат выполнения: изображение, разрешение которого совпадает с разрешением
входного изображения; интенсивность пикселя соответствует классу объектов,
которому принадлежит данная точка на изображении.

### Вывод глубоких моделей средствами асинхронного интерфейса

#### Аргументы командной строки

Название скрипта:

```bash
inference_openvino_async_mode.py
```

Обязательные аргументы:

- `-m / --model` - путь до xml-файла с описанием модели.
- `-w / --weights` - путь до бинарного файла, содержащего веса обученной модели.
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-r / --request` - количество запросов на одновременное выполнения вывода.
  По умолчанию выставляется оптимальное количество запросов, подбирается
  автоматически при использовании асинхронного интерфейса в OpenVINO.
- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-l / --extension` - абсолютный путь к библиотеке
  с реализацией нестандартных слоев для устройств `CPU` и `MYRIAD`.
- `-c / --cldnn_config` - абсолютный путь к библиотеке с реализацией
  нестандартных слоев для устройства `GPU`.
- `-d / --device` - оборудование (`CPU`, `GPU`, `FPGA`, `MYRIAD`),
  на котором будет выполнен прямой проход по сети. По умолчанию вывод осуществляется
  на `CPU`. Также доступны режимы геторогенного исполнения, при котором слои
  сети распределяются между устройствамии, и вывод с одновременным использованием
  нескольких устройств, при котором запросы распределяются между устройствами
  (`HETERO:<Device1>,<Device2>,..`,  `MULTI:<Device1>,<Device2>,..`).
- `--dump` - флаг для сохранения информации об исполнении модели.
- `-p / --priority` - приоритет устройств для вывода с использованием нескольких
  устройств.
- `--labels` - путь до файла с перечнем меток при решении задачи.
  По умолчанию обработка выхода не производится.
- `-nt / --number_top` - число лучших результатов, выводимых
  при решении задачи классификации. По умолчанию выводится `10` наилучших
  результатов.
- `-ni / --number_iter` - количество прямых проходов сети. По умолчанию
  выполняется один проход сети.
- `-nthreads / --number_threads` - максимальное число потоков для исполнения вывода.
  По умолчанию будет использоваться максимальное количество потоков в системе.
- `-nstreams / --number_streams` - максимальное число логических потоков для исполнения
  вывода. По умолчанию выставляется оптимальное значение, подобранное автоматически
  средствами OpenVINO. Оптимальное значение зависит от исполняемого устройства.
- `-t / --task` - наименование решаемой задачи. Для просмотра списка задач используйте
  следующую команду:

  ```bash
  python3 inference_openvino_async_mode.py -h
  ```

- `--color_map` - путь до карты цветов при решении задачи семантической
  сегментации.
- `--prob_threshold` - порог вероятности для фильтрации результатов и
  отбрасывания лишних окаймляющих прямоугольников при решении задачи детектирования
  объектов. По умолчанию равен `0.5`.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.

#### Примеры запуска

**Командная строка для решения задачи классификации изображений**

```bash
python3 inference_openvino_async_mode.py \
    -t classification -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin \
    --labels <path_to_labels>/image_net_synset.txt
```

Результат выполнения: набор наиболее вероятных классов, которым принадлежит
изображение.

**Командная строка для решения задачи детектирования объектов**

```bash
python3 inference_openvino_async_mode.py \
    -t detection -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin
```

Результат выполнения: набор окаймляющих прямоугольников, соответствующих
обнаруженным объектам; изображение, разрешение которого совпадает с разрешением
входного изображения, на котором отображены окаймляющие прямоугольники.

**Командная строка для решения задачи семантической сегментации изображений**

```bash
python3 inference_openvino_async_mode.py \
    -t segmentation -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.xml -w <path_to_weights>/<model_name>.bin \
    --color_map <path_to_color_map>/color_map.txt
```

Результат выполнения: изображение, разрешение которого совпадает с разрешением
входного изображения; интенсивность пикселя соответствует классу объектов,
которому принадлежит даннная точка на изображении.

## Вывод глубоких моделей с использованием Caffe

#### Аргументы командной строки

Название скрипта:

```bash
inference_caffe.py
```

Обязательные аргументы:

- `-m / --model` - путь до prototxt-файла с описанием модели.
- `-w / --weights` - путь до caffemodel-файла, содержащего веса обученной модели.
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-d / --device` - оборудование, на котором будет выполнен проход сети.
  В данный момент вывод осуществляется только на `CPU`.
- `--labels` - путь до файла с перечнем меток при решении задачи.
- `-nt / --number_top` - количество лучших результатов, выводимых
  при решении задачи классификации. По умолчанию выводится `10` наилучших
  результатов.
- `-ni / --number_iter` - количество прямых проходов сети. По умолчанию
  выполняется один проход сети.
- `-t / --task` - наименование решаемой задачи (`classification`,
  `detection`, `segmentation`). По умолчанию обработка выхода не производится.
- `--color_map` - путь до карты цветов при решении задачи семантической
  сегментации.
- `--prob_threshold` - порог вероятности для фильтрации результатов и
  отбрасывания лишних окаймляющих прямоугольников при решении задачи детектирования
  объектов. По умолчанию равен `0.5`.
- `--channel_swap` - порядок перестановки цветовых каналов изображения. Загрузка
  изображений осуществляется в формате BGR (порядок соответствует `(0, 1, 2)`),
  а большинство нейронных сетей принимают на вход изображения в формате RGB,
  поэтому по умолчанию порядок `(2, 1, 0)`.
- `--input_scale` - коэффициент масштабирования изображения. По умолчанию равен `1`.
- `--mean` - параметры для вычитания средних по каждому цветовому каналу изображения.
  По умолчанию `(0, 0, 0)`.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.

#### Примеры запуска

**Командная строка для решения задачи классификации изображений**

```bash
python3 inference_caffe.py \
    -t classification -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.prototxt \
    -w <path_to_weights>/<model_name>.caffemodel \
    --labels <path_to_labels>/image_net_synset.txt
```

Результат выполнения: набор наиболее вероятных классов, которым принадлежит
изображение.

**Командная строка для решения задачи детектирования объектов**

```bash
python3 inference_caffe.py \
    -t detection -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.prototxt \
    -w <path_to_weights>/<model_name>.caffemodel
```

Результат выполнения: набор окаймляющих прямоугольников, соответствующих
обнаруженным объектам; изображение, разрешение которого совпадает с разрешением
входного изображения, на котором отрисованы окаймляющие прямоугольники.

**Командная строка для решения задачи семантической сегментации изображений**

```bash
python3 inference_caffe.py \
    -t segmentation -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.prototxt \
    -w <path_to_weights>/<model_name>.caffemodel \
    --color_map <path_to_color_map>/color_map.txt
```

Результат выполнения: изображение, разрешение которого совпадает с разрешением
входного изображения; интенсивность пикселя соответствует классу объектов,
которому принадлежит даннная точка на изображении.

## Вывод глубоких моделей с использованием TensorFlow

#### Аргументы командной строки

Название скрипта:

```bash
inference_tensorflow.py
```

Обязательные аргументы:

- `-m / --model` - путь до pb-файла или meta-файла с обученной глубокой моделью.
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-d / --device` - оборудование, на котором будет выполнен проход сети.
  В данный момент вывод осуществляется только на `CPU`.
- `-l / --labels` - путь до файла с перечнем меток при решении задачи.
- `-nt / --number_top` - количество лучших результатов, выводимых
  при решении задачи классификации. По умолчанию выводится `10` наилучших
  результатов.
- `-ni / --number_iter` - количество прямых проходов по сети. По умолчанию
  выполняется один проход по сети.
- `-t / --task` - наименование решаемой задачи (`classification`,
  `detection`, `yolo_tiny_voc`, `yolo_v2_coco`, `yolo_v2_tiny_coco`,
  `yolo_v3_tf`, `mask-rcnn`). По умолчанию обработка выхода не выполняется.
- `--prob_threshold` - порог вероятности для фильтрации результатов и
  отбрасывания лишних окаймляющих прямоугольников при решении задачи детектирования
  объектов. По умолчанию равен `0.5`.
- `--channel_swap` - порядок перестановки цветовых каналов изображения. Загрузка
  изображений осуществляется в формате BGR (порядок соответствует `(0, 1, 2)`),
  а большинство нейронных сетей принимают на вход изображения в формате RGB,
  поэтому по умолчанию порядок `(2, 1, 0)`.
- `--input_scale` - коэффициенты масштабирования изображения. По умолчанию `1 1 1`.
- `--mean` - параметры для вычитания средних по каждому цветовому каналу изображения.
  По умолчанию `(0, 0, 0)`.
- `--input_shape` - размеры входного тензора в формате HWC (высота, ширина, число
  каналов). По умолчанию не установлен.
- `--input_names` - название входного узла модели. По умолчанию не установлен.
- `--output_names` - имена выходных узлов модели. По умолчанию не установлен.
- `--num_inter_threads` - количество потоков, используемых для параллелизма
  между независимыми операциями. По умолчанию не установлен и выбирается
  TensorFlow автоматически.
- `--num_intra_threads` - количество потоков, используемых для параллелизма
  между блокирующими операциями. По умолчанию не установлен и выбирается
  TensorFlow автоматически.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `--restrisct_gpu_usage` - ограничение использования видеокарт до 1-й. По умолчанию не установлен.

#### Примеры запуска

**Командная строка для решения задачи классификации изображений**

```bash
python3 inference_tensorflow.py \
    -t classification -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.pb \
    --labels <path_to_labels>/image_net_synset.txt
```

Результат выполнения: набор наиболее вероятных классов, которым принадлежит
изображение.

**Командная строка для решения задачи детектирования объектов**

```bash
python3 inference_tensorflow.py \
    -t detection -i <path_to_image>/<image_name> \
    -m <path_to_model>/<model_name>.pb \
```

Результат выполнения: набор окаймляющих прямоугольников, соответствующих
обнаруженным объектам; изображение, разрешение которого совпадает с разрешением
входного изображения, на котором отрисованы окаймляющие прямоугольники.

## Вывод глубоких моделей с использованием TensorFlow Lite

#### Аргументы командной строки

Название скрипта:

```bash
inference_tensorflowlite.py
```

Обязательные аргументы:

- `-m / --model` - путь до tflite-файла с обученной глубокой моделью.
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-d / --device` - оборудование, на котором будет выполнен проход сети.
  В данный момент вывод осуществляется только на `CPU`.
- `-ni / --number_iter` - количество прямых проходов по сети. По умолчанию
  выполняется один проход по сети.
- `-t / --task` - наименование решаемой задачи (`classification`,
  `detection`, `yolo_tiny_voc`, `yolo_v2_coco`, `yolo_v2_tiny_coco`,
  `yolo_v3_tf`, `mask-rcnn`). По умолчанию обработка выхода не выполняется.
- `--channel_swap` - порядок перестановки цветовых каналов изображения
  в формате `input0[value0],input1[value1]`. Загрузка изображений осуществляется
  в формате BGR (порядок соответствует `(0, 1, 2)`).
- `--input_scale` - коэффициент масштабирования изображения в формате `input0[value0],input1[value1]`.
  По умолчанию равен `1`.
- `--mean` - параметры для вычитания средних по каждому цветовому каналу изображения
  в формате `input0[value0],input1[value1]`. По умолчанию `(0, 0, 0)`.
- `--layout` - формат входных тензоров в формате `input0(value0),input1(value1)`. По умолчанию `NHWC`.
- `--input_shapes` - размеры входных тензоров в формате `input0[value0],input1[value1]`,
  например `input[1,224,224,3]`, порядок размерностей должен соответсвовать формату входного тензора.
  По умолчанию не установлен.
- `--input_names` - название входных узлов модели. По умолчанию не установлен.
- `--output_names` - имена выходных узлов модели. По умолчанию не установлен.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `-nthreads / --number_threads` - максимальное число потоков для исполнения вывода.
  По умолчанию будет использоваться количество потоков, равное числу физических
  ядер в системе.
- `--delegate_ext` - путь до библиотеки с аппаратным ускорением моделей. По умолчанию не установлен.
- `--delegate_options` - настройки для библиотеки с аппаратным ускорением моделей
  в формате "option1: value1; option2: value2". По умолчанию не установлены.

Подробнее про [TFLite Delegates][tflite_delegates]. По умолчанию TensorFlow
использует Flex Delegate для конвертации TF операций в TFLite и их исполнения,
и XNNPACK для ускорения исполнения операций на x86 архитектуре.

#### Примеры запуска

```bash
python3 inference_tensorflowlite.py \
    -m <path_to_model>/<model_name>.tflite \
    -i <path_to_image>/<image_name>
```

## Вывод глубоких моделей с использованием OpenCV DNN Python

#### Аргументы командной строки

Название скрипта:

```bash
inference_opencv.py
```

Обязательные аргументы:

- `-m / --model` - путь до файла с описанием модели
  (расширения файлов `.xml`, `.prototxt` и т.д.).
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-w / --weights` - путь до файла, содержащего веса обученной модели
  (расширения файлов `.bin`, `.caffemodel` и т.д.).
- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-d / --device` - оборудование, на котором выполняется вывод сети.
  Поддерживается вывод на CPU (значение параметра `CPU`), MYRIAD
  (значение параметра `MYRIAD`) и GPU (значение параметра `GPU`).
  По умолчанию принимает значение `CPU`.
- `--precision` - точность весов обученной модели.
  По умолчанию используется `FP32`.
- `--backend` - backend (для OpenCV), с помощью которого будет выполнен
  проход сети. В данный момент доступны `DNN` и `IE`.
  По умолчанию используется `DNN`.
- `--labels` - путь до файла с перечнем меток при решении задачи.
- `-nt / --number_top` - количество лучших результатов, выводимых
  при решении задачи классификации. По умолчанию выводится `5` наилучших
  результатов.
- `-t / --task` - наименование решаемой задачи (`classification`).
  По умолчанию обработка выхода не выполняется.
- `--color_map` - путь до карты цветов при решении задачи семантической
  сегментации.
- `--prob_threshold` - порог вероятности для фильтрации результатов и
  отбрасывания лишних окаймляющих прямоугольников при решении задачи
  детектирования объектов. По умолчанию равен `0.5`.
- `-ni / --number_iter` - количество прямых проходов по сети. По умолчанию
  выполняется один проход по сети.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `-in / --input_name` - название входного узла модели.
  По умолчанию установлено значение `input_`.
- `-on / --output_names` - имена выходных узлов модели.
  По умолчанию не установлен.
- `--input_scale` - коэффициент масштабирования изображения.
  По умолчанию равен `1.0`.
- `--input_shape` - размеры входного тензора в формате HWC
  (высота, ширина, число каналов). По умолчанию: `(224, 224, 3)`.
- `--mean` - параметры для вычитания средних по каждому цветовому каналу
  изображения. По умолчанию `(0, 0, 0)`.
- `--swapRB` - флаг, указывающий на то, надо ли поменять местами
  первый и последний каналы в 3-канальном входном изображении.
  По умолчанию `False`.
- `--crop` - флаг, указывающий на то, будет ли входное изображение
  обрезано после изменения размера. По умолчанию `False`.
- `--layout` - требуемый формат преобразованмя входного тензора.
  По умолчанию `None`. Рекомендуется использовать `NWCH`
  для TensorFlow-моделей, сконвертированных в IR (OpenVINO).

#### Примеры запуска

```bash
python3 inference_opencv.py \
    -m <path_to_model>/<model_name>.<model_file_extension> \
    -w <path_to_weights>/<model_name>.<weights_file_extension> \
    -i <path_to_image>/<image_name>
```

## Вывод глубоких моделей с использованием MXNet (Gluon API)

#### Аргументы командной строки

Название скриптов:

```bash
# синхронный режим
inference_mxnet_sync_mode.py
```

```bash
# асинхронный режим
inference_mxnet_async_mode.py
```

Обязательные аргументы:

- `-m / --model` - путь до описания архитектуры модели
  в формате `.json`, если модель загружается из файла.
  Модель должна быть обучена с использованием Gluon API
  и экспортирована с помощью метода `export`.
- `-w / --weights` - путь до весов обученной модели,
  которые хранятся в файле расширением `.params`,
  если модель загружается из файла. Модель должна быть
  обучена с использованием Gluon API и экспортирована
  с помощью метода `export`.
- `-mn / --model_name` - название модели, если модель
  загружается из [Gluon Model Zoo][gluon_modelzoo].
  При таком варианте запуска модель загружается из сети Интернет.
- `-i / --input` - путь до изображения или директории
  с изображениями (расширения файлов `.jpg`, `.png`,
  `.bmp` и т.д.).
- `-is / --input_shape` - размеры входного тензора сети в формате
  BxCxWxH, B - размер пачки, C - количество каналов изображений,
  W - ширина изображений, H - высота изображений.

Опциональные аргументы:

- `-t / --task` - название задачи. Текущая реализация поддерживает
  решение задачи классификации. По умолчанию принимает значение
  `classification`.
- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-in / --input_name` - название входа модели. По умолчанию модель
  имеет один вход с названием `data`. Текущая реализация вывода
  предусматривает наличие только одного входа.
- `--hybrid` - флаг включения символьных вычислений. По умолчанию
  не установлен.
- `--norm` - флаг необходимости нормировки изображений.
  Выполняется с использованием функции ` mxnet.image.color_normalize`.
  Среднее и среднеквадратическое отклонение, которые принимаются
  на вход указываются в следующих двух аргументах.
- `--mean` - среднее значение интенсивности, которое вычитается
  из изображений в процессе нормировки. Для классификационных моделей
  из [Gluon Model Zoo][gluon_modelzoo], которые обучены на наборе
  данных ImageNet, значение равно `0.485 0.456 0.406`. По умолчанию
  данный параметр принимает значение `0 0 0`.
- `--std` - среднеквадратическое отклонение интенсивности, на которое
  делится значение интенсивности каждого пикселя входного изображения
  в процессе нормировки. Для классификационных моделей
  из [Gluon Model Zoo][gluon_modelzoo], которые обучены на наборе
  данных ImageNet, значение равно `0.229 0.224 0.225`. По умолчанию
  данный параметр принимает значение `1 1 1`.
- `--channel_swap` - порядок перестановки цветовых каналов изображения.
  Загрузка изображений осуществляется в формате BGR (порядок
  соответствует `(0, 1, 2)`), а большинство нейронных сетей принимают
  на вход изображения в формате RGB, поэтому по умолчанию порядок
  `(2, 1, 0)`.
- `-d / --device` - оборудование, на котором выполняется вывод сети.
  Поддерживается вывод на CPU (значение параметра `CPU`) и NVIDIA GPU
  (значение параметра `NVIDIA_GPU`). По умолчанию принимает значение `CPU`.
- `-l / --labels`- путь до файла в формате JSON с перечнем меток
  при решении задачи. По умолчанию принимает значение
  `image_net_labels.json`, что соответствует меткам набора данных
  ImageNet.
- `-ni / --number_iter` - количество прямых проходов по сети.
  По умолчанию выполняется один проход по сети.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `-s / --save_model` - флаг, который определяет необходимость сохранения
  модели, загруженной средствами GluonCV API из репозитория моделей.
  По умолчанию модель не сохраняется. Наличие данной опции обусловлено
  необходимостью последующего запуска компонента Accuracy Checker
  для проверки качества работы модели.
- `-p / --path_save_model` - путь для сохранения файлов модели.
  В процессе сохранения внутри указанной директории создается
  вложенная директория с названием модели `<model_name>`.
  Формируется два файла: `<model_name>-0000.params` - бинарный файл
  с обученными параметрами модели, `<model_name>-symbol.json` - архитектура
  модели в формате .json. По умолчанию модель сохраняется в текущей
  директории.
- `-q / --quantization` - флаг, который определяет необходимость квантизации
  моделей в автоматическом режиме. По умолчанию (в автоматическом режиме запуска тестов бенчмарка)
  не установлен.
- `-cm / --calib_mode` - параметр, который задаёт режим калибровки при
  квантизации модели. По умолчанию (в автоматическом режиме запуска тестов бенчмарка)
  калибровка не применяется (значение `None`).
- `-qdt / --quant_dtype` - параметр, отвечающий за тип весов
  при квантизации моделей. Поддерживаются INT8 и UINT8, по умолчанию
  (в автоматическом режиме запуска тестов бенчмарка) квантизатор сам определит тип весов.
- `-qm / --quantize_mode` - параметр, задающий режим квантизации.
  Доступен полный (full) и умный (smart) режимы.
  По умолчанию (в автоматическом режиме запуска тестов бенчмарка) применяется полный режим.
- `-sqm / --save_quantized_model` - флаг, который определяет
  необходимость сохранения квантизованной модели. По умолчанию не установлен.

#### Примеры запуска

**Запуск вывода в синхронном режиме для модели, которая загружается из Gluon Model Zoo**

```bash
python inference_mxnet_sync_mode.py --model_name <model_name> \
                                    --input <path_to_data> \
                                    --hybrid \
                                    --input_name <input_name> \
                                    --input_shape <input_shape> \
                                    --norm --mean <mean> --std <std> \
                                    --save_model --path_save_model <path_save_model>
```

**Запуск вывода в асинхронном режиме для модели, которая загружается из Gluon Model Zoo**

```bash
python inference_mxnet_async_mode.py --model_name <model_name> \
                                     --input <path_to_data> \
                                     --hybrid \
                                     --input_name <input_name> \
                                     --input_shape <input_shape> \
                                     --norm --mean <mean> --std <std> \
                                     --save_model --path_save_model <path_save_model>
```

**Запуск вывода в синхронном режиме для модели, которая загружается из файлов**

```bash
python inference_mxnet_sync_mode.py --model <file_name>.json \
                                    --weights <file_name>.params \
                                    --input_name <input_name> \
                                    --input_shape <input_shape> \
                                    --input <path_to_data> \
                                    --labels <label_file>.json
```

## Вывод глубоких моделей с использованием PyTorch

#### Аргументы командной строки

Название скрипта:

```bash
inference_pytorch.py
```

Обязательные аргументы:

- `-mn / --model_name` - название модели.
- `-i / --input` - путь до изображения или директории
  с изображениями (расширения файлов `.jpg`, `.png`,
  `.bmp` и т.д.).
- `-is / --input_shape` - размеры входного тензора сети в формате
  BxCxHxW, B - размер пачки, C - количество каналов изображений,
  W - ширина изображений, H - высота изображений.

Опциональные аргументы:

- `-m / --model` - путь до описания архитектуры модели
  в формате `.pt`.
- `-w / --weights` - путь до файла с весами в формате `.pth`.
- `-mm / --module` - путь до Python модуля или относительный путь
  до Python файла с архитектурой модели. По умолчанию, данный параметр
  принимает значение `torchvision.models`, модуль с [моделями][torchvision_models], которые решают
  задачу классификации.
- `-t / --task` - название задачи. Текущая реализация поддерживает
  решение задачи классификации. По умолчанию принимает значение
  `feedforward`.
- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-in / --input_name` - название входа модели. По умолчанию модель
  имеет один вход с названием `data`. Текущая реализация вывода
  предусматривает наличие только одного входа.
- `--mean` - параметры для вычитания средних по каждому цветовому каналу изображения
  в формате `input0[value0],input1[value1]`. По умолчанию `(0, 0, 0)`.
- `--input_scale` - коэффициент масштабирования изображения в формате `input0[value0],input1[value1]`.
  По умолчанию равен `1`.
- `--layout` - формат входных тензоров в формате `input0(value0),input1(value1)`. По умолчанию `NHWC`.
- `--input_shapes` - размеры входных тензоров в формате `input0[value0],input1[value1]`,
  например `input[1,224,224,3]`, порядок размерностей должен соответсвовать формату входного тензора.
  По умолчанию не установлен.
- `--output_names` - название выхода модели. По умолчанию модель
  имеет один вход с названием `output`. Текущая реализация вывода
  предусматривает наличие только одного выхода.
- `-d / --device` - оборудование, на котором выполняется вывод сети.
  Поддерживается вывод на CPU (значение параметра `CPU`) и NVIDIA GPU
  (значение параметра `NVIDIA_GPU`). По умолчанию принимает значение `CPU`.
- `-l / --labels`- путь до файла в формате JSON с перечнем меток
  при решении задачи. По умолчанию принимает значение
  `image_net_labels.json`, что соответствует меткам набора данных
  ImageNet.
- `-ni / --number_iter` - количество прямых проходов по сети.
  По умолчанию выполняется один проход по сети.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `--model_type` - тип модели для запуска. Доступно два режима:
  `baseline` - базовый режим и `scripted` - оптимизированный режим с использованием
  `JIT` (`just in time`) компилятора.
  По умолчанию используется версия `scripted` модели.
- `--inference_mode` - флаг оптимизированного режима прогонки модели
  без хранения информации для тренировки модели.
  По умолчанию данный режим включен.
- `--num_inter_threads` - количество потоков, используемых для параллелизма
  между независимыми операциями. По умолчанию не установлен и выбирается
  PyTorch автоматически.
- `--num_intra_threads` - количество потоков, используемых для параллелизма
  внутри операций. По умолчанию не установлен и выбирается
  PyTorch автоматически.

#### Примеры запуска

**Запуск вывода для модели, которая загружается из TorchVision по умолчанию**

```bash
python inference_pytorch.py --model_name <model_name> \
                            --input <path_to_data> \
                            --input_name <input_name> \
                            --input_shape <input_shape> \
                            --mean <mean> --input_scale <scale> \
                            --batch_size <batch_size>
```

**Запуск вывода для модели, которая загружается из файлов**

```bash
python inference_pytorch.py --model_name <model_name> \
                            --model <file_name>.pt \
                            --input_name <input_name> \
                            --input_shape <input_shape> \
                            --input <path_to_data> \
                            --labels <label_file>.json \
                            --batch_size <batch_size>
```

**Запуск вывода для модели, которая загружается из модуля и отдельного файла с весами**

```bash
python inference_pytorch.py --model_name <model_name> \
                            --module <module_name> \
                            --weights <file_name>.pth \
                            --input_name <input_name> \
                            --input_shape <input_shape> \
                            --input <path_to_data> \
                            --labels <label_file>.json \
                            --batch_size <batch_size>
```

## Вывод глубоких моделей с использованием ONNX Runtime

#### Аргументы командной строки

Название скрипта:

```bash
inference_onnx_runtime.py
```

Обязательные аргументы:

- `-m / --model` - путь до onnx-файла с обученной глубокой моделью.
- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-d / --device` - оборудование, на котором будет выполнен проход сети.
- `--execution_providers` - провайдер, с помощью которого будет выполнен
  проход сети. По умолчанию используется `CPUExecutionProvider`.
  Подробнее про доступные [провайдеры][execution_providers]
- `--precision` - точность весов обученной модели. По умолчанию `None`.
- `-ni / --number_iter` - количество прямых проходов по сети. По умолчанию
  выполняется один проход по сети.
- `-t / --task` - наименование решаемой задачи (`classification`).
  По умолчанию обработка выхода не выполняется.
- `--channel_swap` - порядок перестановки цветовых каналов изображения
  в формате `input0[value0],input1[value1]`. Загрузка изображений осуществляется
  в формате BGR (порядок соответствует `(0, 1, 2)`).
- `--input_scale` - коэффициент масштабирования изображения в формате `input0[value0],input1[value1]`.
  По умолчанию равен `1`.
- `--mean` - параметры для вычитания средних по каждому цветовому каналу изображения
  в формате `input0[value0],input1[value1]`. По умолчанию `(0, 0, 0)`.
- `--layout` - формат входных тензоров в формате `input0(value0),input1(value1)`. По умолчанию `NCHW`.
- `--input_shapes` - размеры входных тензоров в формате `input0[value0],input1[value1]`,
  например `input[1,224,224,3]`, порядок размерностей должен соответсвовать формату входного тензора.
  По умолчанию не установлен.
- `--input_names` - название входных узлов модели. По умолчанию не установлен.
- `--output_names` - имена выходных узлов модели. По умолчанию не установлен.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `-nthreads / --number_threads` - количество потоков, используемых для распараллеливания выполнения внутри узлов.
  По умолчанию устанавливается ONNX Runtime.
- `--number_inter_threads` - количество потоков, используемых для распараллеливания исполнения вывода (между узлами).
  По умолчанию устанавливается ONNX Runtime.
- `--execution_mode` - режим выполнения. По умолчанию устанавливается последовательное выполнение - `ORT_SEQUENTIAL`.

#### Примеры запуска

```bash
python3 inference_onnx_runtime.py \
    -m <path_to_model>/<model_name>.onnx \
    -i <path_to_image>/<image_name>
```
## Вывод глубоких моделей с использованием Apache TVM

#### Аргументы командной строки

Название скрипта:

```bash
inference_tvm.py
```

Обязательные аргументы:

- `-i / --input` - путь до изображения или директории с изображениями
  (расширения файлов `.jpg`, `.png`, `.bmp` и т.д.).
- `-is / --input_shape` - размеры входного тензора сети в формате
  NxHxWxC, B - размер пачки, C - количество каналов изображений,
  W - ширина изображений, H - высота изображений.

Опциональные аргументы:

- `-t / --task` - название задачи. Текущая реализация поддерживает
  решение задачи классификации. По умолчанию принимает значение
  `classification`.
- `--layout` - формат входных тензоров. По умолчанию `NHWС`.
- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-in / --input_name` - название входа модели. По умолчанию модель
  имеет один вход с названием `data`. Текущая реализация вывода
  предусматривает наличие только одного входа.
- `-f / --framework` - фреймворк исходной модели. На данный момент
  поддерживаются модели следующих фреймворков: ONNX Runtime (`onnx`), 
  TensorFlowLite (`tflite`), Caffe (`caffe`), PyTorch (`pytorch`),
  MXNet (`mxnet`) и Apache TVM (`tvm`). 
- `--norm` - флаг необходимости нормировки изображений.
  Среднее и среднеквадратическое отклонение, которые принимаются
  на вход указываются в следующих двух аргументах.
- `--mean` - среднее значение интенсивности, которое вычитается
  из изображений в процессе нормировки. По умолчанию
  данный параметр принимает значение `0 0 0`.
- `--std` - среднеквадратическое отклонение интенсивности, на которое
  делится значение интенсивности каждого пикселя входного изображения
  в процессе нормировки. По умолчанию данный параметр принимает значение `1 1 1`.
- `--channel_swap` - порядок перестановки цветовых каналов изображения.
  Загрузка изображений осуществляется в формате BGR (порядок
  соответствует `(0, 1, 2)`), а большинство нейронных сетей принимают
  на вход изображения в формате RGB, поэтому по умолчанию порядок
  `(2, 1, 0)`.
- `--target` - строка, необходимая для определения аппаратно-зависимых
  оптимизаций. По умолчанию принимает значение `llvm`. Возможные варианты
  можно посмотреть [здесь][tvm_target].
- `-d / --device` - оборудование, на котором выполняется вывод сети.
  Поддерживается вывод на CPU (значение параметра `CPU`).
  По умолчанию принимает значение `CPU`.
- `-l / --labels`- путь до файла в формате JSON с перечнем меток
  при решении задачи. По умолчанию принимает значение
  `image_net_labels.json`, что соответствует меткам набора данных
  ImageNet.
- `-ni / --number_iter` - количество прямых проходов по сети.
  По умолчанию выполняется один проход по сети.
- `-ol / --opt_level` - параметр, определяющий уровень оптимизации
  графа вычислений нейронной сети для ускорения инференса. По умолчанию
  оптимизации не применяются.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.

Аргументы, необходимые для инференса моделей MXNet с использованием Apache TVM:

- `-m / --model` - путь до описания архитектуры модели
  в формате `.json`, если модель загружается из файла.
  Модель должна быть обучена с использованием Gluon API
  и экспортирована с помощью метода `export`.
- `-w / --weights` - путь до весов обученной модели,
  которые хранятся в файле расширением `.params`,
  если модель загружается из файла. Модель должна быть
  обучена с использованием Gluon API и экспортирована
  с помощью метода `export`.
- `-mn / --model_name` - название модели, если модель
  загружается из [Gluon Model Zoo][gluon_modelzoo].
  При таком варианте запуска модель загружается из сети Интернет.
- `-f / --framework` - данный аргумент должен принимать значение `mxnet`.

Аргументы, необходимые для инференса моделей PyTorch с использованием Apache TVM:

- `-m / --model` - путь до описания архитектуры модели
  в формате `.pt`.
- `-w / --weights` - путь до файла с весами в формате `.pth`.
- `-mm / --module` - путь до Python модуля или относительный путь
  до Python файла с архитектурой модели. По умолчанию, данный параметр
  принимает значение `torchvision.models`, модуль с [моделями][torchvision_models], которые решают
  задачу классификации.
- `-mn / --model_name` - имя модели.
- `-f / --framework` - данный аргумент должен принимать значение `pytorch`.

Аргументы, необходимые для инференса моделей ONNX Runtime с использованием Apache TVM:

- `-m / --model` - путь до описания архитектуры модели
  в формате `.onnx`.
- `-mn / --model_name` - имя модели.
- `-f / --framework` - данный аргумент должен принимать значение `onnx`.

Аргументы, необходимые для инференса моделей Caffe с использованием Apache TVM:

- `-m / --model` - путь до описания архитектуры модели
  в формате `.prototxt`.
- `-w / --weights` - путь до файла с весами в формате `.caffemodel`.
- `-f / --framework` - данный аргумент должен принимать значение `caffe`.

Аргументы, необходимые для инференса моделей TVM с использованием Apache TVM:

- `-m / --model` - путь до описания архитектуры модели
  в формате `.json`.
- `-w / --weights` - путь до файла с весами в формате `.params`.
- `-f / --framework` - данный аргумент должен принимать значение `tvm`.

Аргументы, необходимые для инференса моделей TensorFlow Lite с использованием Apache TVM:

- `-m / --model` - путь до описания архитектуры модели
  в формате `.tflite`.
- `-mn / --model_name` - имя модели.
- `-f / --framework` - данный аргумент должен принимать значение `tflite`.

## Вывод глубоких моделей с использованием RKNN

#### Аргументы командной строки

Название скрипта:

```bash
inference_rknn.py
```

Обязательные аргументы:

- `-bch / --benchmark_app` - путь до RKNN бенчмарка.
- `-i / --input` - путь до входных данных
  (расширения файлов `.bin`, `.jpg`, `.png`, `.bmp` и т.д.).

Опциональные аргументы:

- `-m / --model` - путь до файла модели
  (расширение файла `.rknn`).
- `-w / --weights` - путь до файла с весами.
- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `--input_scale` - коэффициент масштабирования изображения.
  По умолчанию равен `1.0`.
- `--input_shape` - размеры входного тензора в формате <[N,C,H,W]>.
- `--dtype` - тип данных входа сети. Пример: "input1[U8],input2[U8]" или только "[U8]"'.
  По умолчанию `[U8]`.
- `--input_scale` - параметры для масштабирования изображения в формате `<[R,G,B]>`.
- `--mean` - параметры для вычитания средних по каждому цветовому каналу изображения в формате `<[R,G,B]>`.
- `-t / --task` - название задачи. По умолчанию принимает значение `without postprocess`.
- `--swap_channels` - параметр переключения каналов. По умолчанию принимает значение `False`.
- `--background` - путь к фоновому изображению.
- `--output_path` - путь для сохранения обработанных выходных данных.
- `--only_process_output` - запуск без выполнения модели.
- `--output_json_path` - путь для сохранения необработанных выходных данных cpp_dl_benchmark.
- `--ref_input` - путь к референсным данным.
- `--use_bin_input` - использование бинарных данных для входа. По умолчанию принимает значение `False`.

#### Примеры запуска

##### Запуск для MXNet

```bash
python3 inference_tvm.py \
    -mn <name_of_model> \
    -i <path_to_image>/<image_name> \
    -ol <number> \
    --input_shape <input_shape> \
    --mean <mean> \
    --std <std> \
    --norm <norm> \
    -f 'mxnet'
```

##### Запуск для PyTorch

```bash
python3 inference_tvm.py \
    -mn <name_of_model> \
    -i <path_to_image>/<image_name> \
    -ol <number> \
    --input_shape <input_shape> \
    --mean <mean> \
    --std <std> \
    --norm <norm> \
    -f 'pytorch'
```

##### Запуск для ONNX Runtime

```bash
python3 inference_tvm.py \
    -m <path_to_model>/<model>.onnx \
    -i <path_to_image>/<image_name> \
    -ol <number> \
    --input_shape <input_shape> \
    --mean <mean> \
    --std <std> \
    --norm <norm> \
    -f 'onnx'
```

##### Запуск для Caffe

```bash
python3 inference_tvm.py \
    -m <path_to_model>/<model>.prototxt \
    -w <path_to_weights>/<weights>.caffemodel
    -i <path_to_image>/<image_name> \
    -ol <number> \
    --input_shape <input_shape> \
    --mean <mean> \
    --std <std> \
    --norm <norm> \
    -f 'caffe'
```

##### Запуск для TVM

```bash
python3 inference_tvm.py \
    -m <path_to_model>/<model>.json \
    -w <path_to_weights>/<weights>.params
    -i <path_to_image>/<image_name> \
    -ol <number> \
    --input_shape <input_shape> \
    --mean <mean> \
    --std <std> \
    --norm <norm> \
    -f 'tvm'
```

##### Запуск для TensorFlow Lite

```bash
python3 inference_tvm.py \
    -m <path_to_model>/<model>.tflite \
    -i <path_to_image>/<image_name> \
    -ol <number> \
    --input_shape <input_shape> \
    --mean <mean> \
    --std <std> \
    --norm <norm> \
    -f 'tflite'
```

##### Запуск для RKNN

```bash
python3 inference_rknn.py \
    -bch <benchmark_path> \
    -m <path_to_model> \
    -d <device NPU> \
    -b <batch size> \
    -i <path_to_input> \
    --shape <input_shape> \
    --layout <layout> \
    --dtype <data_type> \
    --output_path <output_json_path>
```

## Вывод глубоких моделей с использованием Spektral

#### Аргументы командной строки

Название скрипта:

```bash
inference_spektral.py
```

Обязательные аргументы:

- `-m / --model` - путь до keras-файла с обученной глубокой моделью.
- `-i / --input` - путь до графа (расширение `.bin`).

Опциональные аргументы:

- `-b / --batch_size` - количество графов, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `-d / --device` - оборудование, на котором будет выполнен проход сети.
  Поддерживается вывод на CPU (значение параметра `CPU`) и NVIDIA GPU
  (значение параметра `NVIDIA_GPU`). По умолчанию принимает значение `CPU`.
  Для запуска на GPU необходимо установить tensorflow с поддержкой GPU в
  соответствии с [документацией][tensorflow-gpu].
- `-ni / --number_iter` - количество прямых проходов по сети. По умолчанию
  выполняется один проход по сети.
- `-t / --task` - наименование решаемой задачи (`node-classification`).
  По умолчанию обработка выхода не выполняется.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `--restrisct_gpu_usage` - ограничение использования видеокарт до 1-й. По умолчанию не установлен.

#### Примеры запуска

**Командная строка для решения задачи классификации вершин**

```bash
python3 inference_spektral.py \
    -i <path_to_graph>/<graph_name> \
    -m <path_to_model>/<model_name>.keras
```

## Квантизация глубоких моделей с использованием MXNet

#### Аргументы командной строки

```bash
quantization_mxnet.py
```

Обязательные аргументы:

- `-is / --input_shape` - размеры входного тензора, используемые для квантизации модели.

Опциональные аргументы:

- `-m / --model` - путь до json-файла, содержащего информацию о модели.
- `-w / --weights` - путь до params-файла, содержащего веса модели.
- `-mn / --model_name` - название модели, если модель
  загружается из [Gluon Model Zoo][gluon_modelzoo].
  При таком варианте запуска модель загружается из сети Интернет.
- `-cm / --calib_mode` - режим калибровки, применяемый в процессе квантизации модели.
  Доступны следующие режимы: `None`, `Naive`, `Entropy`. В режиме `None`
  калибровка использоваться не будет, а пороговые значения для повторного
  квантования после соответствующих слоев будут рассчитываться во время выполнения
  путем вызова операторов min и max. В режиме `Naive` минимальные и максимальные значения
  выходных данных слоя из набора калибровочных данных будут непосредственно взяты в качестве
  пороговых значений для квантования. В режиме `Entropy` пороговые значения для квантования будут
  определены таким образом, чтобы на основе набора калибровочных данных
  минимизировать расхождение между распределениями выходных данных слоя FP32 и выходными
  данными квантованного слоя. По умолчанию стоит режим `None`.
- `-qdt / --quant_dtype` - тип весов квантизованной модели. Доступны `AUTO`, `INT8` и `UINT8`.
  В случае параметра `AUTO` квантизатор сам примет решение к какому типу весов приводить модель.
  По умолчанию стоит параметр `AUTO`.
- `-qm / --quantize_mode` - режим квантизации. Доступны следующие режимы: `full` и `smart`.
  В случае `full` режима происходит квантизация всех операторов, если это возможно.
  В случае `smart` режима выбор оператора для квантизации будет разумным.
  По умолчанию стоит `full` режим.
- `-d / --device` - оборудование, на котором будет проходить квантизация.
- `-in / --input_name` - название входных узлов модели. По умолчанию не установлен.
- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.

#### Примеры запуска

##### Запуск с произвольными моделями

```bash
python3 quantization_mxnet.py \
        -m <path_to_model>/<model>.json \
        -w <path_to_weights>/<weights>.params \
        -is <input_shape> \ 
```

##### Запуск с моделями из [Gluon Model Zoo][gluon_modelzoo]

```bash
python3 quantization_mxnet.py \
        -mn <name_of_model> \
        -is <input_shape> \
```

## Вывод графовых глубоких моделей с использованием Deep Graph Library (DGL, PyTorch-based)

#### Аргументы командной строки

Название скрипта:

```bash
inference_dgl_pytorch.py
```

Обязательные аргументы:

- `-mn / --model_name` - название модели.
- `-mm / --module` - путь до Python-модуля или относительный путь
  до Python-файла с архитектурой модели.
- `-i / --input` - путь до графа (расширение файла `.bin`).
- `-m / --model` - путь до описания архитектуры модели
  в формате `.pt`.

Опциональные аргументы:

- `--report_path` - путь до отчета работы бенчмарка.
- `-ni / --number_iter` - количество прямых проходов по сети. По умолчанию
  выполняется один проход по сети.
- `-t / --task` - название задачи. Текущая реализация поддерживает
  решение задачи классификации вершин графа. По умолчанию принимает значение
  `feedforward`.
- `-b / --batch_size` - количество графов, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `-d / --device` - оборудование, на котором выполняется вывод сети.
  Поддерживается вывод на CPU (значение параметра `CPU`) и NVIDIA GPU
  (значение параметра `NVIDIA_GPU`). По умолчанию принимает значение `CPU`.
  При запуске на `GPU` необходимо установить пакет под конкретную платформу
  в соответсвии с [документацией][dgl].
- `--time` - время выполнение инференса в секундах. Этот параметр можно 
  задать вместо задать вместо параметра `-ni / --number_iter`. Если 
  одновременно указать и `-ni / --number_iter` и `--time`,
  то будет учитываться тот параметр, при котором инферес работает дольше.
- `--num_inter_threads` - количество потоков, используемых для параллелизма
  между независимыми операциями. По умолчанию не установлен и выбирается
  PyTorch автоматически.
- `--num_intra_threads` - количество потоков, используемых для параллелизма
  внутри операций. По умолчанию не установлен и выбирается
  PyTorch автоматически.

#### Примеры запуска

**Запуск вывода для модели, которая загружается из файла и модуля**

```bash
python inference_dgl_pytorch.py --model_name <model_name> \
                                --module <module_name> \
                                --model <file_name>.pt \
                                --input <path_to_data>
```

## Валидация вывода глубоких моделей с использованием PyTorch (C++ API)

#### Аргументы командной строки

Название скрипта:

```bash
inference_pytorch_cpp.py
```

Обязательные аргументы:

- `-bch / --benchmark_app` - путь до исполнительного файла с реализацией бенчмаркинга с помощью C++ PyTorch.
- `-mn / --model_name` - название модели.
- `-i / --input` - путь до изображения или директории
  с изображениями (расширения файлов `.jpg`, `.png`,
  `.bmp` и т.д.).
- `-in / --input_names` - названия входов модели. Текущая реализация вывода
  предусматривает наличие только одного входа.

Опциональные аргументы:

- `-m / --model` - путь до описания архитектуры модели
  в формате `.pt`.
- `-w / --weights` - путь до файла с весами в формате `.pth`.
- `-mm / --module` - путь до Python модуля или относительный путь
  до Python файла с архитектурой модели. По умолчанию, данный параметр
  принимает значение `torchvision.models`, модуль с [моделями][torchvision_models], которые решают
  задачу классификации.
- `-t / --task` - название задачи. Текущая реализация поддерживает
  решение задачи классификации. По умолчанию принимает значение
  `feedforward`.
- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`.
- `--mean` - параметры для вычитания средних по каждому цветовому каналу изображения
  в формате `input0[value0],input1[value1]`. По умолчанию `(0, 0, 0)`.
- `--input_scale` - коэффициент масштабирования изображения в формате `input0[value0],input1[value1]`.
  По умолчанию равен `1`.
- `--layout` - формат входных тензоров в формате `input0(value0),input1(value1)`. По умолчанию `NHWC`.
- `--input_shapes` - размеры входных тензоров в формате `input0[value0],input1[value1]`,
  например `input[1,224,224,3]`, порядок размерностей должен соответсвовать формату входного тензора.
  По умолчанию не установлен.
- `-d / --device` - оборудование, на котором выполняется вывод сети.
  Поддерживается вывод на CPU (значение параметра `CPU`) и NVIDIA GPU
  (значение параметра `NVIDIA_GPU`). По умолчанию принимает значение `CPU`.
- `-l / --labels`- путь до файла в формате JSON с перечнем меток
  при решении задачи. По умолчанию принимает значение
  `image_net_labels.json`, что соответствует меткам набора данных
  ImageNet.
- `-nt / --number_top` - количество лучших результатов, выводимых
  при решении задачи классификации. По умолчанию выводится `10` наилучших
  результатов.

#### Примеры запуска

**Запуск вывода для модели, которая загружается из модуля**

```bash
python inference_pytorch_cpp.py --module <module_name> \
                                --model_name <model_name> \
                                --input <path_to_data> \
                                --input_names <input_name> \
                                --input_shapes <input_shape> \
                                --mean <mean> --input_scale <scale> \
                                --batch_size <batch_size> \
                                --task classification
```

**Запуск вывода для модели, которая загружается из файлов**

```bash
python inference_pytorch_cpp.py --model_name <model_name> \
                                --model <file_name>.pt \
                                --input_name <input_name> \
                                --input_names <input_name> \
                                --input_shapes <input_shape> \
                                --mean <mean> --input_scale <scale> \
                                --batch_size <batch_size> \
                                --task classification
```

**Запуск вывода для модели, которая загружается из модуля и отдельного файла с весами**

```bash
python inference_pytorch_cpp.py --model_name <model_name> \
                                --module <module_name> \
                                --weights <file_name>.pth \
                                --input_names <input_name> \
                                --input_shapes <input_shape> \
                                --mean <mean> --input_scale <scale> \
                                --batch_size <batch_size> \
                                --task classification
```


## Вывод глубоких моделей с использованием ncnn

#### Аргументы командной строки

Название скриптов:

```bash
inference_ncnn.py
```

Обязательные аргументы:

- `-i / --input` - путь до изображения или директории
  с изображениями (расширения файлов `.jpg`, `.png`,
  `.bmp` и т.д.).
- `-m / --model` - название модели из предложенного списка.

Опциональные аргументы:

- `-in / --input_name` - название входа модели. По умолчанию модель
  имеет один вход с названием `data`. Текущая реализация вывода
  предусматривает наличие только одного входа.
- `-is / --input_shape` - размеры входного тензора сети в формате
  BxHxWxC, B - размер пачки, H - высота изображений,
  W - ширина изображений, C - количество каналов изображений.
  На вход подается в виде четырех целых чисел, разделенных пробелом.
  По умолчанию равно `1 256 256 3`.
- `-b / --batch_size` - количество изображений, которые будут обработаны
  за один проход сети. По умолчанию равно `1`. Значение данного параметра
  должно быть равно значению B из параметра `input_shape`.
- `-l / --labels`- путь до файла в формате JSON с перечнем меток
  при решении задачи. По умолчанию принимает значение
  `image_net_labels.json`, что соответствует меткам набора данных
  ImageNet.
- `-nt / --number_top` - количество лучших результатов, выводимых
  при решении задачи классификации. По умолчанию выводится `5` наилучших
  результатов.
- `-t / --task` - название задачи. Текущая реализация поддерживает
  решение задачи классификации (`classification`), задачи детектирования объектов (`detection`)
  и распознавания лиц (`face-detection`). По умолчанию принимает значение `feedforward`.
- `-ni / --number_iter` - количество прямых проходов по сети.
  По умолчанию выполняется один проход по сети.
- `--raw_output` - работа скрипта без логов. По умолчанию не установлен.
- `-d / --device` - оборудование, на котором выполняется вывод сети.
  Поддерживается вывод на CPU (значение параметра `CPU`) и NVIDIA GPU
  (значение параметра `NVIDIA_GPU`). По умолчанию принимает значение `CPU`.
- `--num_threads` - количество потоков, на которых будет выполняться задача.
  По умолчанию равно `4`.
- `--time` - время выполнения прямых проходов по сети.
- `--threshold` - порог вероятности для задачи детектирования объектов и распознавания лиц.
  По умолчанию равен `0.5`.
- `--report_path` - путь до файла с отчетом в формате `.json`.


#### Примеры запуска

**Запуск вывода для модели, которая загружается из ncnn Model Zoo**

```bash
python inference_ncnn.py --model <model_name> \
                         --input <path_to_data> \
                         --input_name <input_name> \
                         --input_shape <input_shape> \
                         --batch_size <batch_size>
```

<!-- LINKS -->
[execution_providers]: https://onnxruntime.ai/docs/execution-providers
[gluon_modelzoo]: https://cv.gluon.ai/model_zoo/index.html
[tflite_delegates]: https://www.tensorflow.org/lite/performance/delegates
[torchvision]: https://pytorch.org/vision/stable/models.html
[torchvision_models]: https://pytorch.org/vision/0.15/models.html
[tvm_target]: https://tvm.apache.org/docs/reference/api/python/target.html
[dgl]: https://www.dgl.ai/pages/start.html
[tensorflow-gpu]: https://www.tensorflow.org/install/pip
